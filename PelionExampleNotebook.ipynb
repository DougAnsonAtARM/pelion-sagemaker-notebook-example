{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will demonstrate a simple compile and deployment workflow using a ResNet50 pre-trained image recognizer with sample input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define all of our parameters that will be used in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our Sagemaker configuration tunables\n",
    "aws_region = 'us-east-1'\n",
    "aws_s3_folder = \"DEMO-Sagemaker-Edge\"\n",
    "\n",
    "# We will use the ResNet50 image recognition model via Keras framework\n",
    "model_framework = 'keras'\n",
    "model_basename = 'resnet50'\n",
    "model_name = model_framework + \"-\" + model_basename + \"-image-recognizer\"\n",
    "packaged_model_name = model_framework + \"-\" + model_basename + \"-model\"\n",
    "packaged_model_version = \"1.0\"\n",
    "\n",
    "# Input images directory in our notebook...\n",
    "image_paths = './images'\n",
    "\n",
    "# Input images WxH is 224x224 and are color images (so 3 channels)\n",
    "image_size_w       = 224\n",
    "image_size_h       = 224\n",
    "image_num_channels = 3\n",
    "\n",
    "# Our Pelion Edge Gateway is a Nvidia Jetson Xavier\n",
    "target_device = 'jetson_xavier'\n",
    "\n",
    "# Set our Pelion API Configuration Here\n",
    "api_key = 'INSERT_YOUR_PELION_APPLICATION_KEY_HERE'\n",
    "device_id = 'INSERT_YOUR_PELION_XAVIER_EDGE_GATEWAY_DEVICEID_HERE' # Pelion Device ID of our Sagemaker Edge Agent PT device under our Pelion Edge gateway\n",
    "endpoint_api = 'api.' + aws_region + '.mbedcloud.com'              # This is optional and the default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import some additional packages into our python environment... including the pelion/sagemaker controller package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets install some image utilities\n",
    "! pip install ipympl\n",
    "\n",
    "# Core imports for the notebook\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import base64\n",
    "\n",
    "# We will use the ResNet50 Keras model, pre-trained with imagenet weights...\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# ResNet50 helpers used specifically with our selected pre-trained model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# We'll also use time for waiting on predictions to complete...\n",
    "import time\n",
    "\n",
    "# we will also use some helpers from numpy...\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "\n",
    "# Helper for debugging this notebook\n",
    "import importlib\n",
    "\n",
    "# We also need to install the Pelion Sagemaker Controller API\n",
    "! pip install pelion_sagemaker_controller\n",
    "\n",
    "# Method to Decode our ResNet50 based predictions\n",
    "def decode_resnet50_predictions(preds, top=5, class_list_path=None):\n",
    "    if len(preds.shape) != 2 or preds.shape[1] != 1000:\n",
    "        raise ValueError('`decode_predictions` expects '\n",
    "                     'a batch of predictions '\n",
    "                     '(i.e. a 2D array of shape (samples, 1000)). '\n",
    "                     'Found array with shape: ' + str(preds.shape))\n",
    "    class_index = json.load(open(class_list_path))\n",
    "    results = []\n",
    "    for pred in preds:\n",
    "        top_indices = pred.argsort()[-top:][::-1]\n",
    "        result = [tuple(class_index[str(i)]) + (pred[i],) for i in top_indices]\n",
    "        result.sort(key=lambda x: x[2], reverse=True)\n",
    "        results.append(result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import (or uncomment to re-import) the core class for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import example_notebook\n",
    "# importlib.reload(example_notebook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we allocate our notebook class... this will init both Sagamaker as well as the Pelion Controller API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_notebook = example_notebook.MyNotebook(api_key, device_id, endpoint_api, aws_s3_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now... next we prepare our input images and upload them to S3 as preprocessed images for ResNet50 from Keras..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect and prepare our images to analyze\n",
    "print(\"\")\n",
    "print(\"Collecting images from: \" + str(image_paths))\n",
    "my_image_list = [os.path.join(image_paths,filename) for filename in os.listdir(image_paths) if os.path.isfile(image_paths + '/' + filename)]\n",
    "my_image_list_length = len(my_image_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Input Image Files: \" + json.dumps(my_image_list))\n",
    "\n",
    "# preprocess_input() is ResNet50 specific\n",
    "print(\"\")\n",
    "print(\"Pre-processing input image files...\")\n",
    "image_data = my_notebook.read_and_prep_images(my_image_list, image_size_h, image_size_w)\n",
    "preprocessed_images_list = preprocess_input(image_data['array'])\n",
    "\n",
    "# Display our initial images\n",
    "print(\"Displaying Input Images:\")\n",
    "my_notebook.display_images(image_data['img'])\n",
    "\n",
    "# Neo Sagemaker likes NCHW. Our image set is in NHWC... so we must convert it...\n",
    "print(\"\")\n",
    "print(\"Current input shape as NHWC: \" + str(preprocessed_images_list.shape))\n",
    "\n",
    "# Reshape to NCHW\n",
    "nchw_preprocessed_images_list = preprocessed_images_list.transpose(3, 0, 1, 2)\n",
    "# nchw_preprocessed_images_list = preprocessed_images_list\n",
    "\n",
    "print(\"\")\n",
    "print(\"Transposed input shape: \" + str(nchw_preprocessed_images_list.shape))\n",
    "print(\"Transposed input dtype: \" + str(nchw_preprocessed_images_list.dtype))\n",
    "print(\"Transposed data length number of images: \" + str(len(nchw_preprocessed_images_list)))\n",
    "\n",
    "# Save the preprocessed images_list as a single input file locally... \n",
    "input_data_filename = 'preprocessed_images_' + str(time.time()) + '.input'\n",
    "input_data_filename_saved = input_data_filename + '.npy'\n",
    "\n",
    "# save to a numpy-compatible file\n",
    "save(input_data_filename, nchw_preprocessed_images_list)\n",
    "\n",
    "# DEBUG\n",
    "print(\"\")\n",
    "print(nchw_preprocessed_images_list)\n",
    "\n",
    "# Upload the images in the list to S3\n",
    "print(\"\")\n",
    "print('Uploading preprocessed input images to ' + my_notebook.iot_folder + \" in S3 bucket \" + my_notebook.bucket + ' as: ' + input_data_filename_saved + \"...\")\n",
    "print(\"\")\n",
    "my_notebook.sess.upload_data(input_data_filename_saved, my_notebook.bucket, my_notebook.iot_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets import a pre-trained Mobilenet v2 model via TF Hub..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ResNet50 pre-trained model via Keras framework...\n",
    "resnet50_model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Lets dump the model details... \n",
    "print(resnet50_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile up the model and package it for sending down to the edge agent on the gateway..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, lets record the input layer for the Neo-compatible input_shape for Keras-based models...\n",
    "input_layer = resnet50_model.get_layer(index=0)\n",
    "N = my_image_list_length\n",
    "C = image_num_channels\n",
    "H = image_size_h\n",
    "W = image_size_w\n",
    "neo_keras_input_data_shape = {}\n",
    "neo_keras_input_data_shape[input_layer.name] = [N, C, H, W]\n",
    "\n",
    "# Neo likes the input_shape as a stringified json...\n",
    "input_data_shape = json.dumps(neo_keras_input_data_shape)\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Input Data Shape (NCHW format): \" + input_data_shape)\n",
    "\n",
    "# Compile up for our target Pelion Edge Gateway platform type\n",
    "print(\"\")\n",
    "print(\"Initiating Sagemaker Neo compile of \" + model_name + \"...\")\n",
    "job_name = my_notebook.compile_model(resnet50_model, target_device, model_basename, model_framework, input_data_shape)\n",
    "\n",
    "# Package up and store the compiled model onto S3\n",
    "print(\"\")\n",
    "print(\"Packaging up Neo-compiled model and placing in S3...\")\n",
    "model_package = my_notebook.package_model(packaged_model_name, packaged_model_version, job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we (re)load our model since we have just (re)compiled it and (re)packaged it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re)load the model...\n",
    "print('Reloading Model: ' + model_name + \" using package: \" + model_package + '...')\n",
    "print(\"\")\n",
    "my_notebook.pelion_api.pelion_reload_model(model_name,model_package)\n",
    "\n",
    "# Poll every 5 sec to look for the reload() completion....\n",
    "while True:\n",
    "    print(\"Reloading \" + model_name + \"...\")\n",
    "    is_running = my_notebook.pelion_api.pelion_cmd_is_running(\"reloadModel\");\n",
    "    if is_running == False:\n",
    "        print(\"\")\n",
    "        print('Reload Completed!')\n",
    "        print(\"\")\n",
    "        break\n",
    "    time.sleep(5)\n",
    "\n",
    "# Get the loaded model(s) info...\n",
    "reload_result = my_notebook.pelion_api.pelion_list_models();\n",
    "if 'response' in reload_result and len(reload_result['response']) > 0:\n",
    "    if 'name' in reload_result['response'][0]:\n",
    "        print(\"\")\n",
    "        print(\"Currently Loaded Model(s):\")\n",
    "        print(reload_result)\n",
    "else:\n",
    "    print(\"Nodel: \" + model_name + \" did NOT load properly. Check sagemaker edge agent logs on GW.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do a prediction. We will store the results (with a timestamp) back on S3 so that we can pull it back to our notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the prediction with our input image data\n",
    "input_data = 's3:///' + input_data_filename_saved\n",
    "output_result = 's3:///' + model_basename + '-predicted.data'\n",
    "print(\"Invoking Prediction on Pelion Edge with Sagemaker. Model: \" + model_name + \" Input: \" + input_data + \" Output: \" + output_result)\n",
    "print(\"\")\n",
    "my_notebook.pelion_api.pelion_predict(model_name, input_data, output_result)\n",
    "\n",
    "# Poll every 5 sec to look for the predict() completion....\n",
    "while True:\n",
    "    print('Predicting...')\n",
    "    is_running = my_notebook.pelion_api.pelion_cmd_is_running(\"predict\");\n",
    "    if is_running == False:\n",
    "        print(\"\")\n",
    "        print('Prediction Completed!')\n",
    "        print(\"\")\n",
    "        break\n",
    "    time.sleep(5)\n",
    "    \n",
    "# Now get the prediction result\n",
    "prediction_result = my_notebook.pelion_api.pelion_last_cmd_result();\n",
    "if 'details' in prediction_result:\n",
    "    if 'output' in prediction_result['details']:\n",
    "        print(\"\")\n",
    "        print(\"Prediction Results:\")\n",
    "        print(prediction_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we display our results...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction results tensor filename in our notebook\n",
    "prediction_results_tensor_filename = model_basename + '-prediction-output.tensor'\n",
    "\n",
    "# Copy the results back to our notebook\n",
    "print(\"\")\n",
    "print(\"Retrieving result: \" + prediction_result['details']['output'][0]['url'] + \" Saving to: \" + prediction_results_tensor_filename + \"...\")\n",
    "my_notebook.copy_results_to_notebook(prediction_result['details']['output'][0]['url'],prediction_results_tensor_filename)\n",
    "\n",
    "# Read in the output tensor file, convert it, then decode our predictions and display our results...\n",
    "print(\"\")\n",
    "print(\"Opening Output File: \" + prediction_results_tensor_filename + \"...\")\n",
    "file_size = os.path.getsize(prediction_results_tensor_filename)\n",
    "print(\"Prediction Output File Size: \" + str(file_size) + \" bytes\")\n",
    "with open(prediction_results_tensor_filename, 'r') as file:\n",
    "    # Load the JSON-based tensor from its file in our notebook... \n",
    "    json_tensor = json.loads(file.read())\n",
    "    \n",
    "    # Convert the JSON-based tensor to an Numpy Float32 Tensor with the intended shape\n",
    "    b64 = json_tensor['b64_data']\n",
    "    uint8_buffer = base64.b64decode(b64)\n",
    "    output_tensor = np.frombuffer(uint8_buffer, dtype=np.float32)\n",
    "    output_tensor_reshaped = np.reshape(output_tensor,(json_tensor['shape'][0],json_tensor['shape'][1]))\n",
    "    print(output_tensor_reshaped)\n",
    "    \n",
    "    # Display the prediction result tensor details...\n",
    "    print(\"\")\n",
    "    print(\"[JSON Tensor] - Name: \" + json_tensor['name'] + \" Type: \" + str(json_tensor['type']) + \" Desired Shape: \" + str(json_tensor['shape']))\n",
    "    print(\"[JSON Tensor] - Length of Base64 encoded data: \" + str(len(b64)))\n",
    "    print(\"[JSON Tensor] - Base64 decoded buffer length: \" + str(len(buffer)))\n",
    "    print(\"\")\n",
    "    print(\"[Numpy Tensor] - Shape: \" + json.dumps(output_tensor_reshaped.shape) + \" Type: \" + str(output_tensor_reshaped.dtype))\n",
    "    print(output_tensor_reshaped)\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Decoding ResNet50 Imagenet-trained Prediction results...\")\n",
    "    most_likely_labels = decode_resnet50_predictions(output_tensor_reshaped, top=1, class_list_path='./model/imagenet_class_index.json')\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Displaying prediction results...\")\n",
    "    my_notebook.display_images(image_data['img'],most_likely_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done!  As a Data Scientist, I could iterate on re-training the model with additional input data, then recompile/deploy/predict to assess training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG - REMOVE\n",
    "print(\"\")\n",
    "print(\"INPUT [Numpy Tensor] - Shape: \" + str(nchw_preprocessed_images_list.shape) + \" Type: \" + str(nchw_preprocessed_images_list.dtype))\n",
    "np_float_tensor = resnet50_model.predict(nchw_preprocessed_images_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"OUTPUT [Numpy Tensor] - Shape: \" + json.dumps(np_float_tensor.shape) + \" Type: \" + str(np_float_tensor.dtype))\n",
    "print(np_float_tensor)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Decoding ResNet50 Imagenet-trained Prediction results...\")\n",
    "most_likely_labels = decode_resnet50_predictions(np_float_tensor, top=1, class_list_path='./model/imagenet_class_index.json')\n",
    "\n",
    "print(\"\")\n",
    "print(\"Displaying prediction results...\")\n",
    "my_notebook.display_images(image_data['img'],most_likely_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
