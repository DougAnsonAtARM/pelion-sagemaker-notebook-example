{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will demonstrate a simple compile and deployment workflow using a ResNet50 pre-trained image recognizer with sample input images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define all of our parameters that will be used in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will require the \"Tensorflow 2.1 Python 3.6 CPU Optimized\" Kernel.  Other kernels will likely NOT work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup our Sagemaker configuration tunables\n",
    "aws_region = 'us-east-1'\n",
    "aws_s3_folder = \"DEMO-Sagemaker-Edge\"\n",
    "\n",
    "# We will use the ResNet50 image recognition model via Keras framework\n",
    "model_framework = 'keras'\n",
    "model_basename = 'resnet50'\n",
    "model_name = model_framework + \"-\" + model_basename + \"-image-recognizer\"\n",
    "packaged_model_name = model_framework + \"-\" + model_basename + \"-model\"\n",
    "packaged_model_version = \"1.0\"\n",
    "model_package = '{}-{}.tar.gz'.format(packaged_model_name, packaged_model_version)\n",
    "\n",
    "# Decoder classification json specific to ResNet50...\n",
    "resnet50_class_list_path = './model/imagenet_class_index.json'\n",
    "\n",
    "# Input images WxH is 224x224 and are color images (so 3 channels)\n",
    "image_size_w       = 224\n",
    "image_size_h       = 224\n",
    "image_num_channels = 3\n",
    "\n",
    "# Our Pelion Edge Gateway is a Nvidia Jetson Xavier\n",
    "target_device = 'jetson_xavier'\n",
    "\n",
    "# Set our Pelion API Configuration Here\n",
    "api_key = 'INSERT_YOUR_PELION_APPLICATION_KEY_HERE'\n",
    "device_id = 'INSERT_YOUR_PELION_XAVIER_EDGE_SAGE_PT_DEVICEID_HERE' # Pelion Device ID of our Sagemaker Edge Agent PT device under our Pelion Edge gateway\n",
    "endpoint_api = 'api.' + aws_region + '.mbedcloud.com'              # This is optional and the default\n",
    "async_response_sec = 0.25                                          # Pelion long polling tunable. Typically no need to change\n",
    "busy_loop_wait_time_sec = 0.5                                      # This is our busy loop polling interval. Typically no need to change\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import some additional packages into our python environment... including the pelion/sagemaker controller package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets install some image utilities\n",
    "! pip install ipympl\n",
    "\n",
    "# Core imports for the notebook\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "\n",
    "# We will use the ResNet50 Keras model, pre-trained with imagenet weights...\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# ResNet50 helpers used specifically with our selected pre-trained model\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import the Pelion Sagemaker Controller API... this has a notebook helper which will simplify our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pelion_sagemaker_controller\n",
    "from pelion_sagemaker_controller import pelion_sagemaker_controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we allocate our notebook helper. This Helper will allocate a channel to my sagemaker PT device in Pelion and sync the S3 config info with our Sagemaker NB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_notebook = pelion_sagemaker_controller.MyNotebook(api_key, device_id, endpoint_api, aws_s3_folder, async_response_sec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now... next we prepare our input images and upload them to S3 as preprocessed images for ResNet50 from Keras..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input images directory in our notebook...\n",
    "image_paths = './images'\n",
    "\n",
    "# collect and prepare our images to analyze\n",
    "print(\"\")\n",
    "print(\"Collecting images from: \" + str(image_paths))\n",
    "my_image_list = [os.path.join(image_paths,filename) for filename in os.listdir(image_paths) if os.path.isfile(image_paths + '/' + filename)]\n",
    "my_image_list_length = len(my_image_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Input Image Files: \" + json.dumps(my_image_list))\n",
    "\n",
    "# read in the batch of images... then, preprocess_input() is ResNet50 specific\n",
    "print(\"\")\n",
    "print(\"Pre-processing input image files...\")\n",
    "image_data = my_notebook.read_image_batch(my_image_list, image_size_h, image_size_w)\n",
    "preprocessed_images_list = preprocess_input(image_data['array'])\n",
    "\n",
    "# Display our initial images\n",
    "print(\"\")\n",
    "print(\"Displaying Input Images:\")\n",
    "my_notebook.display_images(image_data['img'])\n",
    "\n",
    "#\n",
    "# Neo Sagemaker likes NCHW shapes for Keras models. \n",
    "# Our image set is in NHWC...\n",
    "#\n",
    "print(\"\")\n",
    "print(\"Input shape: \" + str(preprocessed_images_list.shape))\n",
    "print(\"Input dtype: \" + str(preprocessed_images_list.dtype))\n",
    "print(\"Input data length number of images: \" + str(len(preprocessed_images_list)))\n",
    "\n",
    "# ...so transpose() to NCHW format...  we have to do this because Neo requires a NCHW layer...\n",
    "preprocessed_images_list = tf.transpose(preprocessed_images_list,[0, 3, 1, 2])\n",
    "\n",
    "# Neo-compatible input tensor shape now!\n",
    "print(\"\")\n",
    "print(\"Neo transposed Input shape: \" + str(preprocessed_images_list.shape))\n",
    "print(\"Neo transposed Input dtype: \" + str(preprocessed_images_list.dtype))\n",
    "print(\"Neo transposed Input data length number of images: \" + str(len(preprocessed_images_list)))\n",
    "\n",
    "# Save the preprocessed images, as the input tensor, to a single input file in S3\n",
    "input_data_filename = 'preprocessed_images_' + str(time.time()) + '.input'\n",
    "my_notebook.save_input_tensor_to_s3(preprocessed_images_list,input_data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets import a pre-trained Mobilenet v2 model via TF Hub..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ResNet50 pre-trained model via Keras framework...\n",
    "print(\"Allocating ResNet50 model\")\n",
    "resnet50_model = ResNet50(weights=\"imagenet\", pooling=\"avg\")\n",
    "    \n",
    "# Lets dump the model details... \n",
    "print(resnet50_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile up the model and package it for sending down to the edge agent on the gateway..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, lets record the input layer for the Neo-compatible input_shape for Keras-based models...\n",
    "input_layer = resnet50_model.get_layer(index=0)\n",
    "\n",
    "# Neo wants me to build out a specific input_shape (in NCHW per above...) for the compile() task...\n",
    "neo_input_layer_shape = {}\n",
    "neo_input_layer_shape[input_layer.name] = [my_image_list_length, image_num_channels, image_size_h, image_size_w]\n",
    "neo_input_layer_shape = json.dumps(neo_input_layer_shape)\n",
    "print(\"\")\n",
    "print(\"Neo expects this input_shape if compiling a Keras model: \" + neo_input_layer_shape)\n",
    "\n",
    "# Compile up for our target Pelion Edge Gateway platform type\n",
    "print(\"\")\n",
    "print(\"Initiating Sagemaker Neo compile of \" + model_name + \"...\")\n",
    "job_name = my_notebook.compile_model(resnet50_model, target_device, model_basename, model_framework, neo_input_layer_shape)\n",
    "\n",
    "# Package up and store the compiled model onto S3\n",
    "print(\"\")\n",
    "print(\"Packaging up Neo-compiled model and placing in S3...\")\n",
    "model_package = my_notebook.package_model(packaged_model_name, packaged_model_version, job_name)\n",
    "print(\"\")\n",
    "print(\"Model Package: \" + model_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we (re)load our model since we have just (re)compiled it and (re)packaged it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (re)load the newly compiled model...\n",
    "print('Reloading Model: ' + model_name + \" in package: \" + model_package + '...')\n",
    "print(\"\")\n",
    "my_notebook.pelion_api.pelion_reload_model(model_name,model_package)\n",
    "\n",
    "# Poll every 5 sec to look for the reload() completion....\n",
    "while True:\n",
    "    print(\"Reloading \" + model_name + \"...\")\n",
    "    is_running = my_notebook.pelion_api.pelion_cmd_is_running(\"reloadModel\");\n",
    "    if is_running == False:\n",
    "        print(\"\")\n",
    "        print('Reload Completed!')\n",
    "        print(\"\")\n",
    "        time.sleep(10)\n",
    "        break\n",
    "    time.sleep(20)\n",
    "\n",
    "# Get the loaded model info via Pelion...\n",
    "reload_result = my_notebook.pelion_api.pelion_list_models();\n",
    "if 'response' in reload_result and len(reload_result['response']) > 0:\n",
    "    if 'name' in reload_result['response'][0]:\n",
    "        print(\"\")\n",
    "        print(\"Currently Loaded Model(s):\")\n",
    "        print(reload_result)\n",
    "else:\n",
    "    print(\"Model: \" + model_name + \" did NOT load properly. Check sagemaker edge agent logs on GW.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets do a prediction. We will store the results (with a timestamp) back on S3 so that we can pull it back to our notebook..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the prediction with our input image data via Pelion using the S3 URLs for input and outputs...\n",
    "input_tensor_s3 = 's3:///' + input_data_filename\n",
    "output_tensor_s3 = 's3:///' + model_basename + '-predicted.data'\n",
    "print(\"Invoking Prediction on Pelion Edge with Sagemaker. Model: \" + model_name + \" Input Tensor: \" + input_tensor_s3 + \" Output Tensor: \" + output_tensor_s3)\n",
    "print(\"\")\n",
    "my_notebook.pelion_api.pelion_predict(model_name, input_tensor_s3, output_tensor_s3)\n",
    "\n",
    "# Poll every busy_loop_wait_time_sec seconds to look for the predict() completion....\n",
    "while True:\n",
    "    print('Predicting...')\n",
    "    is_running = my_notebook.pelion_api.pelion_cmd_is_running(\"predict\");\n",
    "    if is_running == False:\n",
    "        print(\"\")\n",
    "        print('Prediction Completed!')\n",
    "        print(\"\")\n",
    "        break\n",
    "    time.sleep(busy_loop_wait_time_sec)\n",
    "    \n",
    "# Now get the prediction result\n",
    "prediction_result = my_notebook.pelion_api.pelion_last_cmd_result();\n",
    "if 'details' in prediction_result:\n",
    "    if 'output' in prediction_result['details']:\n",
    "        print(\"\")\n",
    "        print(\"Prediction Results:\")\n",
    "        print(prediction_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we display our results...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction results tensor filename in our notebook\n",
    "output_tensor_local_nb_filename = model_basename + '-prediction-output.tensor'\n",
    "\n",
    "# Read the output tensor from S3 and deposit a copy of the output into the notebook. our output tensor should be float32 for Resnet50...\n",
    "output_tensor = my_notebook.get_output_tensor(prediction_result['details']['output'][0]['url'], output_tensor_local_nb_filename, np.float32)\n",
    "\n",
    "# Decode the Resnet50 prediction results\n",
    "print(\"\")\n",
    "print(\"Decoding ResNet50 Imagenet-trained Prediction results...\")\n",
    "most_likely_labels = my_notebook.decode_resnet50_predictions(output_tensor, top=1, class_list_path=resnet50_class_list_path)\n",
    "\n",
    "# Display the images, annotated with the predictions\n",
    "print(\"\")\n",
    "print(\"Displaying prediction results...\")\n",
    "my_notebook.display_images(image_data['img'],most_likely_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! Well... maybe not quite... as a Data Scientist, I could iterate re-training the model with additional input data, new layers/etc... then recompile/deploy/predict to assess training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try another batch of inputs... maybe some more dogs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new inputs\n",
    "# Input images directory in our notebook...\n",
    "image_paths = './images_2'\n",
    "\n",
    "print(\"\")\n",
    "print(\"Loading up a new batch of images from: \" + image_paths + \"...\")\n",
    "\n",
    "# collect and prepare our images to analyze\n",
    "print(\"\")\n",
    "print(\"Collecting images from: \" + str(image_paths))\n",
    "my_image_list = [os.path.join(image_paths,filename) for filename in os.listdir(image_paths) if os.path.isfile(image_paths + '/' + filename)]\n",
    "my_image_list_length = len(my_image_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Input Image Files: \" + json.dumps(my_image_list))\n",
    "\n",
    "# read in the batch of images... then, preprocess_input() is ResNet50 specific\n",
    "print(\"\")\n",
    "print(\"Pre-processing input image files...\")\n",
    "image_data = my_notebook.read_image_batch(my_image_list, image_size_h, image_size_w)\n",
    "preprocessed_images_list = preprocess_input(image_data['array'])\n",
    "\n",
    "# Display our initial images\n",
    "print(\"\")\n",
    "print(\"Displaying Input Images:\")\n",
    "my_notebook.display_images(image_data['img'])\n",
    "\n",
    "#\n",
    "# Neo Sagemaker likes NCHW shapes for Keras models. \n",
    "# Our image set is in NHWC...\n",
    "#\n",
    "print(\"\")\n",
    "print(\"Input shape: \" + str(preprocessed_images_list.shape))\n",
    "print(\"Input dtype: \" + str(preprocessed_images_list.dtype))\n",
    "print(\"Input data length number of images: \" + str(len(preprocessed_images_list)))\n",
    "\n",
    "# ...so transpose() to NCHW format...  we have to do this because Neo requires a NCHW layer...\n",
    "preprocessed_images_list = tf.transpose(preprocessed_images_list,[0, 3, 1, 2])\n",
    "\n",
    "# Neo-compatible input tensor shape now!\n",
    "print(\"\")\n",
    "print(\"Neo transposed Input shape: \" + str(preprocessed_images_list.shape))\n",
    "print(\"Neo transposed Input dtype: \" + str(preprocessed_images_list.dtype))\n",
    "print(\"Neo transposed Input data length number of images: \" + str(len(preprocessed_images_list)))\n",
    "\n",
    "# Save the preprocessed images, as the input tensor, to a single input file in S3\n",
    "input_data_filename = 'preprocessed_images_' + str(time.time()) + '.input'\n",
    "my_notebook.save_input_tensor_to_s3(preprocessed_images_list,input_data_filename)\n",
    "\n",
    "# Now we invoke predict() again on the edge gw with the new batch...\n",
    "print(\"\")\n",
    "print(\"Invoking predict() via Pelion Edge to process new batch of images from: \" + image_paths + \"...\")\n",
    "print(\"\")\n",
    "\n",
    "# Invoke the prediction with our input image data via Pelion using the S3 URLs for input and outputs...\n",
    "input_tensor_s3 = 's3:///' + input_data_filename\n",
    "output_tensor_s3 = 's3:///' + model_basename + '-predicted.data'\n",
    "print(\"Invoking Prediction on Pelion Edge with Sagemaker. Model: \" + model_name + \" Input Tensor: \" + input_tensor_s3 + \" Output Tensor: \" + output_tensor_s3)\n",
    "print(\"\")\n",
    "my_notebook.pelion_api.pelion_predict(model_name, input_tensor_s3, output_tensor_s3)\n",
    "\n",
    "# Poll every busy_loop_wait_time_sec seconds to look for the predict() completion....\n",
    "while True:\n",
    "    print('Predicting...')\n",
    "    is_running = my_notebook.pelion_api.pelion_cmd_is_running(\"predict\");\n",
    "    if is_running == False:\n",
    "        print(\"\")\n",
    "        print('Prediction Completed!')\n",
    "        print(\"\")\n",
    "        break\n",
    "    time.sleep(busy_loop_wait_time_sec)\n",
    "    \n",
    "# Now get the prediction result\n",
    "prediction_result = my_notebook.pelion_api.pelion_last_cmd_result();\n",
    "if 'details' in prediction_result:\n",
    "    if 'output' in prediction_result['details']:\n",
    "        print(\"\")\n",
    "        print(\"Prediction Results:\")\n",
    "        print(prediction_result)\n",
    "        \n",
    "# Lastly we interpret the new prediction results\n",
    "print(\"\")\n",
    "print(\"Decoding the prediction results from the new batch of images in: \" + image_paths + \"...\")\n",
    "print(\"\")\n",
    "\n",
    "# Prediction results tensor filename in our notebook\n",
    "output_tensor_local_nb_filename = model_basename + '-prediction-output.tensor'\n",
    "\n",
    "# Read the output tensor from S3 and deposit a copy of the output into the notebook. our output tensor should be float32 for Resnet50...\n",
    "output_tensor = my_notebook.get_output_tensor(prediction_result['details']['output'][0]['url'], output_tensor_local_nb_filename, np.float32)\n",
    "\n",
    "# Decode the Resnet50 prediction results\n",
    "print(\"\")\n",
    "print(\"Decoding ResNet50 Imagenet-trained Prediction results...\")\n",
    "most_likely_labels = my_notebook.decode_resnet50_predictions(output_tensor, top=1, class_list_path=resnet50_class_list_path)\n",
    "\n",
    "# Display the images, annotated with the predictions\n",
    "print(\"\")\n",
    "print(\"Displaying prediction results...\")\n",
    "my_notebook.display_images(image_data['img'],most_likely_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and lets not forget the cat-lovers... lets try some predictions on cat pictures..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new inputs\n",
    "# Input images directory in our notebook...\n",
    "image_paths = './images_3'\n",
    "\n",
    "print(\"\")\n",
    "print(\"Loading up a new batch of images from: \" + image_paths + \"...\")\n",
    "\n",
    "# collect and prepare our images to analyze\n",
    "print(\"\")\n",
    "print(\"Collecting images from: \" + str(image_paths))\n",
    "my_image_list = [os.path.join(image_paths,filename) for filename in os.listdir(image_paths) if os.path.isfile(image_paths + '/' + filename)]\n",
    "my_image_list_length = len(my_image_list)\n",
    "\n",
    "print(\"\")\n",
    "print(\"Input Image Files: \" + json.dumps(my_image_list))\n",
    "\n",
    "# read in the batch of images... then, preprocess_input() is ResNet50 specific\n",
    "print(\"\")\n",
    "print(\"Pre-processing input image files...\")\n",
    "image_data = my_notebook.read_image_batch(my_image_list, image_size_h, image_size_w)\n",
    "preprocessed_images_list = preprocess_input(image_data['array'])\n",
    "\n",
    "# Display our initial images\n",
    "print(\"\")\n",
    "print(\"Displaying Input Images:\")\n",
    "my_notebook.display_images(image_data['img'])\n",
    "\n",
    "#\n",
    "# Neo Sagemaker likes NCHW shapes for Keras models. \n",
    "# Our image set is in NHWC...\n",
    "#\n",
    "print(\"\")\n",
    "print(\"Input shape: \" + str(preprocessed_images_list.shape))\n",
    "print(\"Input dtype: \" + str(preprocessed_images_list.dtype))\n",
    "print(\"Input data length number of images: \" + str(len(preprocessed_images_list)))\n",
    "\n",
    "# ...so transpose() to NCHW format...  we have to do this because Neo requires a NCHW layer...\n",
    "preprocessed_images_list = tf.transpose(preprocessed_images_list,[0, 3, 1, 2])\n",
    "\n",
    "# Neo-compatible input tensor shape now!\n",
    "print(\"\")\n",
    "print(\"Neo transposed Input shape: \" + str(preprocessed_images_list.shape))\n",
    "print(\"Neo transposed Input dtype: \" + str(preprocessed_images_list.dtype))\n",
    "print(\"Neo transposed Input data length number of images: \" + str(len(preprocessed_images_list)))\n",
    "\n",
    "# Save the preprocessed images, as the input tensor, to a single input file in S3\n",
    "input_data_filename = 'preprocessed_images_' + str(time.time()) + '.input'\n",
    "my_notebook.save_input_tensor_to_s3(preprocessed_images_list,input_data_filename)\n",
    "\n",
    "# Now we invoke predict() again on the edge gw with the new batch...\n",
    "print(\"\")\n",
    "print(\"Invoking predict() via Pelion Edge to process new batch of images from: \" + image_paths + \"...\")\n",
    "print(\"\")\n",
    "\n",
    "# Invoke the prediction with our input image data via Pelion using the S3 URLs for input and outputs...\n",
    "input_tensor_s3 = 's3:///' + input_data_filename\n",
    "output_tensor_s3 = 's3:///' + model_basename + '-predicted.data'\n",
    "print(\"Invoking Prediction on Pelion Edge with Sagemaker. Model: \" + model_name + \" Input Tensor: \" + input_tensor_s3 + \" Output Tensor: \" + output_tensor_s3)\n",
    "print(\"\")\n",
    "my_notebook.pelion_api.pelion_predict(model_name, input_tensor_s3, output_tensor_s3)\n",
    "\n",
    "# Poll every busy_loop_wait_time_sec seconds to look for the predict() completion....\n",
    "while True:\n",
    "    print('Predicting...')\n",
    "    is_running = my_notebook.pelion_api.pelion_cmd_is_running(\"predict\");\n",
    "    if is_running == False:\n",
    "        print(\"\")\n",
    "        print('Prediction Completed!')\n",
    "        print(\"\")\n",
    "        break\n",
    "    time.sleep(busy_loop_wait_time_sec)\n",
    "    \n",
    "# Now get the prediction result\n",
    "prediction_result = my_notebook.pelion_api.pelion_last_cmd_result();\n",
    "if 'details' in prediction_result:\n",
    "    if 'output' in prediction_result['details']:\n",
    "        print(\"\")\n",
    "        print(\"Prediction Results:\")\n",
    "        print(prediction_result)\n",
    "        \n",
    "# Lastly we interpret the new prediction results\n",
    "print(\"\")\n",
    "print(\"Decoding the prediction results from the new batch of images in: \" + image_paths + \"...\")\n",
    "print(\"\")\n",
    "\n",
    "# Prediction results tensor filename in our notebook\n",
    "output_tensor_local_nb_filename = model_basename + '-prediction-output.tensor'\n",
    "\n",
    "# Read the output tensor from S3 and deposit a copy of the output into the notebook. our output tensor should be float32 for Resnet50...\n",
    "output_tensor = my_notebook.get_output_tensor(prediction_result['details']['output'][0]['url'], output_tensor_local_nb_filename, np.float32)\n",
    "\n",
    "# Decode the Resnet50 prediction results\n",
    "print(\"\")\n",
    "print(\"Decoding ResNet50 Imagenet-trained Prediction results...\")\n",
    "most_likely_labels = my_notebook.decode_resnet50_predictions(output_tensor, top=1, class_list_path=resnet50_class_list_path)\n",
    "\n",
    "# Display the images, annotated with the predictions\n",
    "print(\"\")\n",
    "print(\"Displaying prediction results...\")\n",
    "my_notebook.display_images(image_data['img'],most_likely_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I can run the model within the notebook itself to confirm that I get the same result as with the compiled version on my xavier board:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Because we are NOT running the model via Neo here, and because Resnet50 is channels-last by default,\n",
    "# we need to re-transpose the images back to channel-last...\n",
    "#\n",
    "output_original_shaped_list = tf.transpose(preprocessed_images_list, [0, 2, 3, 1])\n",
    "print(\"Input Tensor: (reshaped) Shape: \" + str(output_original_shaped_list.shape) + \" Type: \" + str(output_original_shaped_list.dtype))\n",
    "\n",
    "# Perform a prediction directly in the notebook with our model...\n",
    "direct_prediction_results = resnet50_model.predict(output_original_shaped_list)\n",
    "\n",
    "# Display the prediction results tensor info...\n",
    "print(\"Output Tensor - Shape: \" + json.dumps(direct_prediction_results.shape) + \" Type: \" + str(direct_prediction_results.dtype))\n",
    "\n",
    "# Decode the predictions in the exact same way as we did with Neo...\n",
    "print(\"\")\n",
    "print(\"Decoding ResNet50 Imagenet-trained Prediction results...\")\n",
    "most_likely_labels = my_notebook.decode_resnet50_predictions(direct_prediction_results, top=1, class_list_path=resnet50_class_list_path)\n",
    "\n",
    "# Display the image results\n",
    "print(\"\")\n",
    "print(\"Displaying prediction results...\")\n",
    "my_notebook.display_images(image_data['img'],most_likely_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.1 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.1-cpu-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
